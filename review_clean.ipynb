{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "diio2YBXr03Y",
    "outputId": "e207f611-19fb-4778-c357-72e120620fbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbstripout in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
      "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from nbstripout) (5.10.4)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->nbstripout) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->nbstripout) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from nbformat->nbstripout) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.11/dist-packages (from nbformat->nbstripout) (5.7.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->nbstripout) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->nbstripout) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->nbstripout) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->nbstripout) (0.24.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->nbstripout) (4.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat->nbstripout) (4.13.2)\n",
      "Could not strip 'review.ipynb': file not found\n"
     ]
    }
   ],
   "source": [
    "!pip install nbstripout\n",
    "!nbstripout review.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a03-vJA2HXAi",
    "outputId": "c9d18f93-bd0d-40da-d746-28861e05b836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8YJCp01AGdqv",
    "outputId": "7760218b-90ec-4997-c3a4-939ea404feb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Enter the place name: Bar Totti's\n",
      "üåê en reviews are collecting...\n",
      "üåê ko reviews are collecting...\n",
      "üåê es reviews are collecting...\n",
      "üåê zh-CN reviews are collecting...\n",
      "üåê ja reviews are collecting...\n",
      "‚úÖ 25 reviews are saved in 'bar_totti's_cleaned.txt'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "from transformers import pipeline\n",
    "\n",
    "# 1. system setting\n",
    "API_KEY = 'AIzaSyCwG6NWnXFHdMTIsmVFaduVu-MqbBUq6fQ'  # ‚ö†Ô∏è Google API KEY\n",
    "BASE_PATH = \"/content/drive/MyDrive/NLP/GoogleReview\"\n",
    "os.makedirs(BASE_PATH, exist_ok=True)\n",
    "\n",
    "# 2. place_id searching\n",
    "def get_place_id(place_name, language='en'):\n",
    "    url = f\"https://maps.googleapis.com/maps/api/place/textsearch/json?query={place_name}&language={language}&key={API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    result = response.json()\n",
    "    if result['status'] == 'OK':\n",
    "        return result['results'][0]['place_id']\n",
    "    else:\n",
    "        print(\"‚ùå Can't find a place.\")\n",
    "        return None\n",
    "\n",
    "# 3. Collect review\n",
    "def get_reviews(place_id, language='en'):\n",
    "    url = f\"https://maps.googleapis.com/maps/api/place/details/json?place_id={place_id}&fields=reviews&language={language}&key={API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    reviews = response.json().get('result', {}).get('reviews', [])\n",
    "    return [{\n",
    "        \"author\": r.get(\"author_name\", \"\"),\n",
    "        \"text\": r.get(\"text\", \"\"),\n",
    "        \"time\": r.get(\"time\", 0),\n",
    "        \"datetime\": datetime.fromtimestamp(r.get(\"time\", 0)).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        \"lang\": language\n",
    "    } for r in reviews]\n",
    "\n",
    "# 4. translate function\n",
    "def translate_to_english(text, source_lang):\n",
    "    if source_lang == 'en':\n",
    "        return text\n",
    "    url = \"https://translation.googleapis.com/language/translate/v2\"\n",
    "    params = {\n",
    "        'q': text,\n",
    "        'source': source_lang,\n",
    "        'target': 'en',\n",
    "        'format': 'text',\n",
    "        'key': API_KEY\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(url, data=params)\n",
    "        result = response.json()\n",
    "        if \"error\" in result:\n",
    "            print(\"‚ùå translate API errror:\")\n",
    "            print(f\"üîπ original text: {text[:80]}...\")\n",
    "            print(f\"üîπ error message: {result['error'].get('message')}\")\n",
    "            return None\n",
    "        return result['data']['translations'][0]['translatedText']\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è exception occurs during translation:\")\n",
    "        print(f\"üîπ original text: {text[:80]}...\")\n",
    "        print(f\"üîπ exceptional message: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# 5. save eng version after translated\n",
    "def save_clean_reviews(place_name, reviews):\n",
    "    filename = place_name.lower().replace(\" \", \"_\") + \"_cleaned.txt\"\n",
    "    file_path = os.path.join(BASE_PATH, filename)\n",
    "\n",
    "    existing = set()\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    r = json.loads(line.strip())\n",
    "                    existing.add((r['author'], r['time']))\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    new_count = 0\n",
    "    with open(file_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        for r in reviews:\n",
    "            key = (r[\"author\"], r[\"time\"])\n",
    "            if key not in existing:\n",
    "                if r[\"lang\"] != \"en\":\n",
    "                    translated = translate_to_english(r[\"text\"], r[\"lang\"])\n",
    "                    if translated:\n",
    "                        r[\"text\"] = translated\n",
    "                    else:\n",
    "                        continue  # skip when fail translation\n",
    "                # ‚úÖ remove non-english review\n",
    "                r.pop(\"lang\", None)\n",
    "                r.pop(\"text_translated\", None)\n",
    "                f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "                new_count += 1\n",
    "\n",
    "    if new_count > 0:\n",
    "        print(f\"‚úÖ {new_count} reviews are saved in '{filename}'.\")\n",
    "    else:\n",
    "        print(f\"‚ÑπÔ∏è no more new review.\")\n",
    "\n",
    "# 6. review function\n",
    "def run_review_translation_pipeline():\n",
    "    place_name = input(\"üîç Enter the place name: \").strip()\n",
    "    if not place_name:\n",
    "        print(\"‚ùó plcae name doesn't exist .\")\n",
    "        return\n",
    "\n",
    "    langs = ['en', 'ko', 'es', 'zh-CN', 'ja']\n",
    "    place_id = get_place_id(place_name)\n",
    "    if not place_id:\n",
    "        return\n",
    "\n",
    "    total_reviews = []\n",
    "    for lang in langs:\n",
    "        print(f\"üåê {lang} reviews are collecting...\")\n",
    "        reviews = get_reviews(place_id, language=lang)\n",
    "        total_reviews.extend(reviews)\n",
    "\n",
    "    save_clean_reviews(place_name, total_reviews)\n",
    "\n",
    "# 7. implement\n",
    "run_review_translation_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c5yN8ZfyHJKI",
    "outputId": "5b1f2c3b-10bc-4cad-a5c3-4dcf021d33d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "q4v7oaN9HXGC"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# Function to automatically find the latest cleaned file\n",
    "def find_latest_cleaned_file(base_path):\n",
    "    list_of_files = glob.glob(os.path.join(base_path, '*_cleaned.txt'))  # Find all *_cleaned.txt files\n",
    "    if not list_of_files:\n",
    "        print(\"‚ùó Cannot find any cleaned file.\")\n",
    "        return None\n",
    "    latest_file = max(list_of_files, key=os.path.getmtime)  # Select the most recently modified file\n",
    "    return latest_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z2L9e-3NHXo-",
    "outputId": "8e47a6ae-7dab-47fc-eefa-7ee708082840"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Latest cleaned file path: /content/drive/MyDrive/NLP/GoogleReview/bar_totti's_cleaned.txt\n"
     ]
    }
   ],
   "source": [
    "#Automatically find the latest cleaned file\n",
    "BASE_PATH = \"/content/drive/MyDrive/NLP/GoogleReview\"\n",
    "file_path = find_latest_cleaned_file(BASE_PATH)\n",
    "\n",
    "if file_path:\n",
    "    print(f\"‚úÖ Latest cleaned file path: {file_path}\")\n",
    "\n",
    "    # Load review data\n",
    "    reviews = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                review = json.loads(line)\n",
    "                text = review.get(\"text_translated\") or review.get(\"text\")\n",
    "                if text:\n",
    "                    reviews.append({\"text\": text})\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    df = pd.DataFrame(reviews)\n",
    "    df.head()\n",
    "else:\n",
    "    print(\"‚ùå Cannot proceed: no cleaned file found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332,
     "referenced_widgets": [
      "067336c9c5684a6da34ec05a6e686685",
      "ff2aa1fbb6f7422f9aaf852998a1379c",
      "ef7fc76058144ea3871ea787921099e2",
      "cf0b8669e2ea49afa18bc6113947ef1a",
      "1f8706b25dee4d16a34296682a0eff7f",
      "e8557d0b5b614551bb968db2546030bc",
      "5b2f5c39a5114a9cba2a9753c36e2df5",
      "51c1369fe1f74ef2aa6c393459a4f2d2",
      "89fa036c4d614fa591b65490becc7b21",
      "441f21eee33548dfb39e8f07c17b8f96",
      "486f34e3236245bca9a8868c622dd405",
      "7dfaded90ec74d458751723770ee6e5d",
      "3131221255cd4f8eb02f047e316f7df7",
      "45bf698eeab24d889a00962e9f7bd9be",
      "0ce73f213913423a99fc900c97367311",
      "29d5fd8ee3544d4693557289e586c838",
      "91b755a5bed5416396f0c43b2715dced",
      "4c36109fb93943799b66d985b2eb486a",
      "9e31339ddde14873a20e9fd4b9cc499c",
      "28c5022fd6c9415bac3bce8fc400c66d",
      "5f165af4edde486f9657f33315f40e1e",
      "d14025cce2ec4cce93caebbf357fd2de",
      "59a05d0f14854c93b9ad9756b28155c3",
      "8e8855a9e4f5443bb04db53d48a403c6",
      "52051b6fad124969a891ba53597c4011",
      "5438bc5d7d334ba193545da13fd43fb4",
      "b7fba0e4f0d7483386bfb71c38dd7adf",
      "0f8696dd14d244f68356b10bcaae4169",
      "fd7f244e106f45728eb7fcf2b9df1cb4",
      "72e76ab5dfaa4b6d83ada9c007a633ff",
      "65af0d683a6343d293312ca98f6a0d2e",
      "7d2c963016bd4a188b45d7b77a7f7902",
      "27843da7776342019956d28de4153ea4",
      "e0f8d2bdcc8642529bae075fe5e5c745",
      "2bc9882d358642b8a73410a8786457bf",
      "656d6fc7325f4ac889783d951e3f3313",
      "d49d572963794f40b38b589125362428",
      "9e1ce05088eb4ecdbde8144ebd0a6ba2",
      "02b675d4769348209c4240731bce81ba",
      "8f6b1f984bd84c7bb2ebf536e15e2db7",
      "98d8aaf692af4fc593be048e50738831",
      "d9e3d83c89fd4c9e8622a27f8c36bb19",
      "82475aced1a84c619398c2d6f3c6ccaa",
      "55908b6cd0b1440880f7c60a0cee82b5",
      "859affcf427545fc9481eee8c91c8a79",
      "e6862833f0464f9bb41034945f97649f",
      "860b1765797b41e7a08f82e33277cbfa",
      "ddeb84e0cb1c49a080e93f63ff8b678f",
      "0a4027d1de9c432983423a7e97aa18dc",
      "b426b2ebfa3f4ab5a075ede6d951e986",
      "712dcd4c3980437da312c65a6a609378",
      "2c150865f4b642bcb60dd7776dfae30c",
      "7934e7fc385546c2a418ad4640df3818",
      "b050fecea83d439d83a3fc76bab69c9e",
      "f18ebb23b5804cee8fc90d40ff21324f"
     ]
    },
    "id": "RxbrvT3r8DZM",
    "outputId": "dab651c7-50be-468d-ae7a-d07962b0ac85"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "067336c9c5684a6da34ec05a6e686685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/953 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dfaded90ec74d458751723770ee6e5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/669M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a05d0f14854c93b9ad9756b28155c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/39.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f8d2bdcc8642529bae075fe5e5c745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859affcf427545fc9481eee8c91c8a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load sentiment analysis model (predicts 1 to 5 stars)\n",
    "star_model = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "# Function to convert star rating to sentiment label\n",
    "def convert_star_to_label(label):\n",
    "    stars = int(label.split()[0])\n",
    "    if stars <= 2:\n",
    "        return 0  # Negative\n",
    "    elif stars == 3:\n",
    "        return 1  # Neutral\n",
    "    else:\n",
    "        return 2  # Positive\n",
    "\n",
    "# Final sentiment analysis function\n",
    "def analyze_sentiment_star(text):\n",
    "    try:\n",
    "        result = star_model(text[:512])[0]\n",
    "        return convert_star_to_label(result[\"label\"])\n",
    "    except:\n",
    "        return 1  # Treat as neutral if an exception occurs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "y1FECOIB_7R7",
    "outputId": "2baaf551-0002-4ee6-b25b-45b69fc92e40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Sentiment distribution:\n",
      "label\n",
      "Negative üò°     4\n",
      "Neutral üòê      2\n",
      "Positive üòä    19\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df[[\\\"text\\\", \\\"label\\\"]]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The Asian girl at the front desk might be a little tired. The service attitude seemed perfunctory. And they asked you to sit in the street on the side. Don't go there. It was freezing. But the white lady inside and the male bartender at the bar were really nice. Because of them, we moved inside and had a perfect experience. And we chose the bar based on our pictures. It was really delicious!! This is my third time here. I think I will come again [By the way, they have an Italian beer, which is really delicious]\",\n          \"This restaurant had a great atmosphere and the dinner was delicious. A special mention goes to Clara, the Spanish woman who helped us choose dishes from the menu and recommended two gluten-free pasta dishes that were delicious. We recommend it, and if you speak Spanish, ask for her; she's charming and very professional.\",\n          \"You can not find pizza here, but their wood fired bread really compensates it. Very good with lot very wide variation of menu / topping to accompany your bread. Salami, mushroom, olive, tomato, burata, tuna, octopus, etc.\\nAlso order their vongole bucatini and it\\u2019s also very good and well textured homemade pasta.\\nTiramisu also good.\\n\\nThe service is very fast.\\nLove the ambience, also.\\nThey have indoor and outdoor seating, but i love the outdoor one facing to George street :)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 2,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-b93b7179-da8c-46da-8968-36fd502e2339\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The best restaurant in Ssinni ü•á\\nIt was worth ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The Asian girl at the front desk might be a li...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can not find pizza here, but their wood fi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>This is a popular restaurant in Sydney.\\nI thi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>This restaurant had a great atmosphere and the...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b93b7179-da8c-46da-8968-36fd502e2339')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-b93b7179-da8c-46da-8968-36fd502e2339 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-b93b7179-da8c-46da-8968-36fd502e2339');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-4cbbfbec-76d8-4b56-a967-e6ec7921de9e\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4cbbfbec-76d8-4b56-a967-e6ec7921de9e')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-4cbbfbec-76d8-4b56-a967-e6ec7921de9e button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                 text  label\n",
       "8   The best restaurant in Ssinni ü•á\\nIt was worth ...      2\n",
       "16  The Asian girl at the front desk might be a li...      2\n",
       "0   You can not find pizza here, but their wood fi...      2\n",
       "23  This is a popular restaurant in Sydney.\\nI thi...      2\n",
       "11  This restaurant had a great atmosphere and the...      2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply sentiment labeling\n",
    "df[\"label\"] = df[\"text\"].apply(analyze_sentiment_star)\n",
    "\n",
    "# Summarize sentiment distribution\n",
    "label_names = {0: \"Negative üò°\", 1: \"Neutral üòê\", 2: \"Positive üòä\"}\n",
    "label_counts = df[\"label\"].value_counts().sort_index().rename(index=label_names)\n",
    "\n",
    "print(\"üìä Sentiment distribution:\")\n",
    "print(label_counts)\n",
    "\n",
    "# Check sample entries\n",
    "df[[\"text\", \"label\"]].sample(5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rv5s1L2lbY9m",
    "outputId": "c54f4005-48ac-4a46-8caa-aa384b93b514"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-3.6.0 dill-0.3.8 fsspec-2025.3.0 multiprocess-0.70.16 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572,
     "referenced_widgets": [
      "63e58f8c9fbe48f197f5c4d0aab78834",
      "bf97c28363ef497fb87d7152771536ab",
      "44728ebc0b154dfca4f9b0ac7f2c69d0",
      "bcc13d5798bd43878abde612c0bf49c8",
      "d82c70b3c35649e19c9f31905b53f82b",
      "6a5c930cdac048faa352f0f68093dab8",
      "bdf17cdc61184e9fb95ed3faced63976",
      "90fd4c97436c48f28239a96abc904b25",
      "b4bf327d7815471d849d08590cc46121",
      "a5f4eae808b04145acdb9da401d80fd1",
      "34509ba2f2a44bfcaf2f445b66cde12b",
      "9c828b80e5214e728139e4dc4dea7960",
      "e344b33aaf004ddab9ab58e5a1da48bd",
      "080132043714420795621f92f7a5a2f3",
      "2f181328c45547d5bb61131be8b2b4d8",
      "225d688cee664d14b431224438110020",
      "c1721fce711c4dfabdb2a1692ec1db4c",
      "b65e995a31d1440ba0d58d8c0cf88852",
      "4cf3b546f9c34a988e18204d5c0a083a",
      "64277c475ed34884be793fdd27cc99c0",
      "4cb3fa4958c0420ea60c6299497b038d",
      "27779d1f61ce4e69b679263f7bfda3fc",
      "00b56f0d2c08491d82749b0bd4c2e20d",
      "94728564e05e4b1d8a077d284017b78c",
      "38d065e0b70044b4b30f8284f67de9ca",
      "ac6e3c8ff8c64c05a5e43885612554ab",
      "adca4bf3ced6459aba8aea1479d66b4a",
      "dc5509abfea543a6b0274756fad7cf82",
      "3e2ffbc0e76447f6b3f91cb5e6fe5750",
      "3fcdbf14d5334898b6a9a2715520d243",
      "f42ed6e3f5804a948c297493a6ca78a6",
      "93561b1716c349fcb917a31e50dec6a2",
      "554aaa58825f4e54943dfaec52daca8e",
      "56f3c3b5c8c645c58f630ce97e909123",
      "42b90f91bedd4908b495fe2429f589bb",
      "503b592a67af4f13b09fb5b0b4d33c68",
      "bf5e74a06e4946b4934ef9808dd91e00",
      "3733e075d9534b53a475dd83e9f45d6b",
      "725ad175c07d45408612e96f6e80fc46",
      "a437eb5706364f7baebdc6afac994599",
      "71355aafa66d46e5a744e5bb39ca9bb8",
      "ba434a5777a9453e9d92f337b7891d5b",
      "bd18d1a72d7c4349ba5014d10c117ccb",
      "d6ca7669f7d142c68067ae3d99d81a25",
      "107e04b7e0944f3c8c6e6c60b4c9192d",
      "48e7dcdd46f14aeb98ddd95e0d141d30",
      "39097f4f1590401eaec73f85516e1f62",
      "74ad8c52308b466da68400e80e9ef4b6",
      "bff1e225b17a4eefae7ae623c87c20bb",
      "f66cdbefa1a540ae8da43e131d3f3eee",
      "c6768b563a794c06b35c5bf87358dbf7",
      "1f2aa1df4c344ea1a8088ed9d3cabc57",
      "7a13f1e8b220427185178ecc7730ca05",
      "8728232ec1d84f87a4fe2186df238572",
      "e00d9411ad2e4991b2433763fb8e313d",
      "65832e1d6b714948849f1dfb84a007af",
      "308291e1bb004950a5eacfb2609d3326",
      "dfc4a01f9b27443287d0fc3263c20139",
      "27bb587c9849407db74b5316a6309dae",
      "dc8fdda66755474ab4b3daf3301fa5de",
      "34892e4779ea438da86bd11f07dc5935",
      "c5b5973919a74cc39391c6a501ce0194",
      "38b3bc2bb9e143e988be03cf1cc4690a",
      "290d9804d613408487bf5ecac1a36113",
      "0626588f6a6b48f58049f3c5849bcc29",
      "2dc101cbb55a41e7aefb6a2877ded101",
      "d09bb8c2202144ef85d7877cb9dd74dd",
      "a5cf86a22b2e4c549ee3d90cb5809a14",
      "371f0cad36eb4c03801314014e2abcb5",
      "75c057b6ba6649748badb14a802ce6a1",
      "374a0a4eae77433fae959af7adaea43d",
      "d79dfca03fc54242a019fdf04bbf0e16",
      "492ea8f80b16468aa1b424a5041cb146",
      "be641a1c4b1a49c8a18b43fce582f114",
      "d2556d6334e146b6a8268194ac003207",
      "d9bd9be7891244db86c11c65fc2c1330",
      "b63f7cd628dd4aa1bf491d409c985a4a"
     ]
    },
    "id": "1wVmjoIa28yL",
    "outputId": "3aa54346-7f8e-4fd2-c783-6ec262cebd9f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e58f8c9fbe48f197f5c4d0aab78834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c828b80e5214e728139e4dc4dea7960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b56f0d2c08491d82749b0bd4c2e20d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f3c3b5c8c645c58f630ce97e909123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107e04b7e0944f3c8c6e6c60b4c9192d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65832e1d6b714948849f1dfb84a007af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09bb8c2202144ef85d7877cb9dd74dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 01:21, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Sample predictions on validation set:\n",
      "                                                text  label  predicted_label\n",
      "1  I came here a year ago while traveling.\\nThis ...      2                2\n",
      "3  üìçBar Totti‚Äôs, 330A/330B George St, Sydney NSW ...      2                2\n",
      "0  You can not find pizza here, but their wood fi...      2                2\n",
      "2  Without a doubt one of my favorite places in S...      2                2\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, pipeline\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Disable W&B (Weights & Biases)\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "# 1. Check number of reviews by sentiment\n",
    "label_counts = df[\"label\"].value_counts()\n",
    "has_positive = label_counts.get(2, 0) >= 2\n",
    "has_negative = label_counts.get(0, 0) >= 2\n",
    "has_single_negative = label_counts.get(0, 0) == 1\n",
    "\n",
    "# 2. If there are enough positive reviews ‚Üí Train a model\n",
    "if has_positive:\n",
    "    from transformers import BertTokenizer, BertForSequenceClassification\n",
    "    from datasets import Dataset\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # Split positive reviews into train/validation sets\n",
    "    positive_df = df[df[\"label\"] == 2]\n",
    "    train_df, val_df = train_test_split(positive_df, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Convert to HuggingFace Dataset\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "    def tokenize_fn(batch):\n",
    "        return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "    train_dataset = Dataset.from_pandas(train_df).map(tokenize_fn, batched=True)\n",
    "    val_dataset = Dataset.from_pandas(val_df).map(tokenize_fn, batched=True)\n",
    "    train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "    val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "\n",
    "    # Set up Trainer and train the model\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=\"./logs\"\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # Add predictions to validation set\n",
    "    predictions = trainer.predict(val_dataset)\n",
    "    pred_labels = predictions.predictions.argmax(axis=1)\n",
    "    val_df = val_df.reset_index(drop=True)\n",
    "    val_df[\"predicted_label\"] = pred_labels\n",
    "\n",
    "    # Print a sample of predictions without errors\n",
    "    n = min(5, len(val_df))\n",
    "    print(\"üìä Sample predictions on validation set:\")\n",
    "    print(val_df[[\"text\", \"label\", \"predicted_label\"]].sample(n, random_state=42))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232,
     "referenced_widgets": [
      "0c7b728f8f7f4c31ba3e58ec63155d05",
      "35ec55928e8a4403ab73388289c3f984",
      "9e4c784d8759470fa276016b0d98c325",
      "1e90a369f2a64a6f804572f2fbe42a24",
      "8477abbbe62a4e5b89a0444265077dd9",
      "f2c4251d1474420a884329aebd2f0fa0",
      "e422818ec6d144a79cfb6458ac1c34b9",
      "3e2df6b67f274c4282be9d7b13fb7714",
      "d63b60159b3b4bd291147da63459df1f",
      "6372734a4f0d4e8b9da951e99c25fd82",
      "78e2d29896744132aab3f966aa59e51d",
      "68b1889ed5594e899c2909bc22a8dbe7",
      "1f953ea4b2764da5913d7d210a20ac60",
      "d34ac11330be4b6f98cf5e197dba30ba",
      "25d12278d4ca4bc0882485d78c05624a",
      "7f9136d66a0d48488fac31660e38a2da",
      "446e072391904b0d83f79e51641eec72",
      "2271ed1397eb43efb01538a0837869f7",
      "d3e6aaacee934460b2ed229c54cde954",
      "b3b38caafdd3498daa0aa978aaffa8d4",
      "48320594013743d290a557c5abc82f30",
      "38e7b3b1e3cc47d29c6094dcf94654d9",
      "564fc23385a34a3e99bfda910d502cd2",
      "08a2e1aa0b134b8bb018c3d6a1d890e5",
      "93be304d4bdf4346a69ce2207ab94be0",
      "71395aa2d3a64d37af3df863689a2658",
      "618d7d8fa2ea4603b76ac5863233311b",
      "d61da8b0771745aeb87fc39f2d17e717",
      "bf7c28b029d54de8b09ad9708a2cd25a",
      "69f2e7fb4f97462086972a429d6617f4",
      "14653cb0efa2437baf2e8fe1ef5125df",
      "45cd8a57c0924a4492f77a358e368031",
      "de3911645c644f049ac88d940e96a73a",
      "0976c1705de8493e9c175d17897671db",
      "797e3518231c43ba8a4347fb6ed33ef8",
      "98ca016de8bf4f2eb334b53cd5274789",
      "bd55f48551e34207a64dfae3c4c06d1f",
      "671ff5a955014f62b5ed4327ee87089c",
      "c0c6347fcbc444bfa07178c9490e3fda",
      "5e9b6988ee0f46448b6a40c65d787d5b",
      "e0498b8d2d9e476d8990890f155c8ff9",
      "3a2c477a5dc746a9a2c8a345126c9460",
      "d6d98ea71b2440aaa8bce677486d5097",
      "033b01fbae694fb08af0335ad8f5e560",
      "8a5b97f0f52a47cdb6f0bed5e7d7ed4e",
      "0de8e53e8e4b4432a67736d1e52970b5",
      "eddc0242197749edb8fec546b54bb58b",
      "7f8a92fdc47c43c4905320609ff054f7",
      "7828f1533e694007a836296b4740df56",
      "0944476d1171404dad73355c56a7bf98",
      "d0ff31c65dca4824be7ebe1392a36a42",
      "2c047b0894d2457abfd1c342763cdfae",
      "9e8f615583e44ce7a8cfe6aba1cbb07f",
      "cf13eb9391d744b180761bd905613af7",
      "c34bbe8163144c1b868d580283124d44",
      "1de2aa085c9d435c99c9040fdffc1be6",
      "2302e73f7489491fbdf1f2831136c74a",
      "0aba5bcdbb004e0b94db69c1e5e6acb7",
      "76260d6b7508494586ab106996737168",
      "cc443ddfe9354789b8e47bdfea7e969f",
      "822706fdc4dd45e18368f2f4a03a50a3",
      "935927f7cc1e43bb839ac0e89f77076f",
      "f66e847be663446b845d36922678a982",
      "16547967073e4e718f76663bc552303c",
      "b65d99f4ba5b43928058a2e06d68ad94",
      "89adf5566ddb4a479a964e34b26b5582"
     ]
    },
    "id": "-K4YxW-38DTo",
    "outputId": "44761591-cebe-45fb-929c-75a53b033263"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c7b728f8f7f4c31ba3e58ec63155d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68b1889ed5594e899c2909bc22a8dbe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "564fc23385a34a3e99bfda910d502cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0976c1705de8493e9c175d17897671db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5b97f0f52a47cdb6f0bed5e7d7ed4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de2aa085c9d435c99c9040fdffc1be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 1. Load summarization model (using BART)\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "# 2. Function for individual summarization + final summarization\n",
    "def summarize_reviews_by_compression(text_list, chunk_size=512, final_maxlen=100):\n",
    "    individual_summaries = []\n",
    "\n",
    "    for text in text_list:\n",
    "        try:\n",
    "            # Summarize each individual review\n",
    "            summary = summarizer(text[:chunk_size], max_length=60, min_length=20, do_sample=False)[0][\"summary_text\"]\n",
    "            individual_summaries.append(summary)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    if not individual_summaries:\n",
    "        return \"‚ö†Ô∏è No text available for summarization.\"\n",
    "\n",
    "    # Combine individual summaries and summarize again\n",
    "    combined = \" \".join(individual_summaries)[:3000]  # Limit the total length\n",
    "    try:\n",
    "        final_summary = summarizer(combined, max_length=final_maxlen, min_length=40, do_sample=False)[0][\"summary_text\"]\n",
    "    except:\n",
    "        final_summary = \"‚ö†Ô∏è Final summarization failed\"\n",
    "\n",
    "    return final_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vf1vdpw88DQw",
    "outputId": "c47bcf73-7292-4f2c-e87f-bae322fa4323"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 60, but your input_length is only 46. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=23)\n",
      "Your max_length is set to 60, but your input_length is only 47. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=23)\n",
      "Your max_length is set to 60, but your input_length is only 39. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n",
      "Your max_length is set to 60, but your input_length is only 35. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n"
     ]
    }
   ],
   "source": [
    "# List of positive review texts\n",
    "positive_reviews = df[df[\"label\"] == 2][\"text\"].tolist()\n",
    "\n",
    "# Handle negative reviews\n",
    "negative_count = df[\"label\"].value_counts().get(0, 0)\n",
    "\n",
    "# Summarize positive reviews\n",
    "positive_summary = summarize_reviews_by_compression(positive_reviews)\n",
    "\n",
    "# Summarize or directly output negative review(s)\n",
    "if negative_count == 1:\n",
    "    negative_summary = df[df[\"label\"] == 0][\"text\"].iloc[0]\n",
    "elif negative_count >= 2:\n",
    "    negative_reviews = df[df[\"label\"] == 0][\"text\"].tolist()\n",
    "    negative_summary = summarize_reviews_by_compression(negative_reviews)\n",
    "else:\n",
    "    negative_summary = \"‚ùå No negative reviews\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N14guKrY8PS6",
    "outputId": "edfbffa3-7593-40b4-b15c-5a43b67cde9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Summary of Positive Reviews:\n",
      " Bar Totti's in Sydney is an excellent choice for good food and a lively atmosphere. Although there is often a wait, it's usually under 30 minutes, and it's definitely worth it. The fresh taste, rich flavor, and chewy bread are really appealing.\n",
      "\n",
      "‚ùå Summary of Negative Reviews:\n",
      " \"The wait time was really too long, and the waiter didn't look happy\" \"The fettuccine was amazing! We also had beef cutlet!\" \"Perhaps they didn't understand English, but there was a misunderstanding\"\n"
     ]
    }
   ],
   "source": [
    "print(\"‚úÖ Summary of Positive Reviews:\\n\", positive_summary)\n",
    "print(\"\\n‚ùå Summary of Negative Reviews:\\n\", negative_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SX6Wy3afCreI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
